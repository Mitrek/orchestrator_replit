Great logs—thank you. From these lines:

* `points:100, hotspotsCount:5, fallback:false`
* “Screenshot attempt 1/2 failed: Timeout after 7000ms” (then request still 200)

…it’s **very unlikely** the 1×1 dummy PNG is the culprit here. The second screenshot provider kicked in (hence `fallback:false` on the AI side and a normal base64 length), and you’re consistently returning 200 with non-trivial durations. So screenshots are (eventually) fine.

The blank image behavior matches a **coordinate handling bug** inside `server/services/aiHeatmap.ts`:

## What’s happening

* You **normalize the hotspots** (divide by `viewport.width/height`), **then** call `hotspotsToPoints` with a fake viewport `{ width: 1, height: 1 }`.
* `hotspotsToPoints` expects **normalized hotspots + the real viewport** so it can generate **pixel points**. With `{1,1}`, everything collapses into the top-left, producing points at `(0,0)` (or near it).
* You then pass those (pixel) points directly to `renderFromPoints`, which expects **normalized** points. Because the points are basically `(0,0)`, the rendered heat is invisible / looks blank.

## Quick, surgical fix (drop-in)

In `server/services/aiHeatmap.ts`:

### 1) Fix knob clamping (avoid `alpha=0` invisibility)

Replace the truthy checks with explicit `!== undefined` checks:

```ts
const clamp = (v: number, min: number, max: number) => Math.max(min, Math.min(max, v));
const clampedKnobs = knobs ? {
  ...knobs,
  alpha: knobs.alpha !== undefined ? clamp(knobs.alpha, 0.1, 1) : undefined,
  kernelRadiusPx: knobs.kernelRadiusPx !== undefined ? clamp(knobs.kernelRadiusPx, 8, 96) : undefined,
  kernelSigmaPx: knobs.kernelSigmaPx !== undefined ? clamp(knobs.kernelSigmaPx, 2, 48) : undefined
} : undefined;
```

### 2) Generate points with the **real viewport**, then re-normalize for the renderer

Replace your “normalize then { width:1,height:1 }” block:

```ts
// BEFORE (problem):
// const normalizedHotspots = finalHotspots.map(h => ({
//   ...h,
//   x: h.x / viewport.width,
//   y: h.y / viewport.height
// }));
// const points = hotspotsToPoints(normalizedHotspots, { width: 1, height: 1 }, 800);

// AFTER (fix):
// finalHotspots are already normalized [0..1] by the AI.
// 1) Use the real viewport to get *pixel* points.
// 2) Convert those pixel points back to normalized for the renderer.
const pxPoints = hotspotsToPoints(finalHotspots, viewport, 800);
const points = pxPoints.map(p => ({
  x: p.x / viewport.width,
  y: p.y / viewport.height,
  weight: p.weight
}));
```

That’s it. With this change:

* `hotspotsToPoints` distributes points across the **actual page area**.
* `renderFromPoints` receives normalized points as it expects and scales to the **actual screenshot dimensions**.

## Optional guards (helpful while you test)

Add these quick checks after the screenshot and before rendering:

```ts
if (screenshotPng.length < 200) {
  console.warn("[/api/v1/heatmap] Screenshot buffer is tiny — likely placeholder/dummy.");
}

const maxX = Math.max(...points.map(p => p.x));
const maxY = Math.max(...points.map(p => p.y));
if (maxX <= 0.005 && maxY <= 0.005) {
  console.warn("[/api/v1/heatmap] Points look collapsed near (0,0) — check viewport/normalization.");
}
```

## Why your logs still showed `points:100`

`hotspotsToPoints` enforces a minimum per-hotspot point count (e.g., 20), so with 5 hotspots you’ll see `100` even if every point sits at `(0,0)`. That’s why the metric looked “healthy” while the image looked blank.

## Sanity test after patch

Run the same four requests you just ran. In the server log, verify:

* `points` stays \~100+ (that’s fine).
* **No “collapsed near (0,0)” warning**.
* The returned `base64` decodes to a PNG with visible heat.

If anything still looks off after this change, paste me the `meta` block again (and if possible, your current `knobs` payload). But I’m confident this fixes the blank output you’re seeing.
