Yes—we can skip legacy for now and finish the **full heatmap feature** cleanly. Here’s a precise Step 3 brief for your Replit assistant that **does not touch legacy at all** and hardens the AI path end-to-end.

---

# Step 3 — Finish the Full Heatmap Feature (AI-only, production-ready)

**Goal:** Make `/api/v1/heatmap` rock-solid: retries, caching, timeouts, knobs, and a tiny client harness. Leave legacy completely out.

**Do not change:** `/api/v1/heatmap/data` or `/api/v1/heatmap/hotspots`.

---

## A) Files to add / modify

### 1) `server/services/hotspotsCache.ts` (new, in-memory cache)

* Exports:

  * `key(parts: { url:string; device:"desktop"|"tablet"|"mobile"; parity:boolean; promptHash:string }): string`
  * `get(k: string): { ts:number; hotspots: Hotspot[]; meta:any } | undefined`
  * `set(k: string, hotspots: Hotspot[], meta:any): void`
* TTL: **10 minutes**.
* Implementation: `Map<string, {ts,hotspots,meta}>`.

### 2) `server/services/screenshot.ts` (provider-only robustness)

* Keep provider-only path (no Puppeteer).
* Add **retry** logic:

  * Try Provider A, then Provider B (if available), with per-attempt timeout **7s**.
  * If both fail, throw a typed `ScreenshotError("PROVIDER_FAILED")`.
* Return `{ png:Buffer, viewport }` exactly as Step 2.

### 3) `server/services/aiHotspots.ts` (prompt + guardrails)

* Add **promptHash** computation (sha256 of the final prompt string).
* Add **hard timeouts** for the OpenAI call (e.g., 15s).
* On **any** model error or invalid JSON → produce **fallback hotspots** (no throws).
* Ensure post-sanitization rules remain:

  * clamp to \[0,1], drop width/height ≤ 0, **confidence floor 0.25**, IoU < 0.4, **max 8**.

### 4) `server/services/aiHeatmap.ts` (orchestrator) — add cache + knobs

* New env flags (with defaults):

  * `HOTSPOTS_CACHE="true" | "false"` (default `"true"`)
  * `PARITY_MODE="true" | "false"` (default `"true"`)
* Build **cache key** with `{ url, device, parity, promptHash }`.
  If `HOTSPOTS_CACHE !== "false"` and a hit exists → use cached hotspots (set `meta.ai.cached=true`).
* Accept optional `knobs` from request and **clamp** them to safe ranges:

  * `alpha: 0.1..1`, `kernelRadiusPx: 8..96`, `kernelSigmaPx: 2..48`, etc.
* Log one JSON line including `{ cached, points: points.length, hotspotsCount }`.

### 5) `server/routes.ts` (or your mounted router)

* **/api/v1/heatmap** (AI image route):

  * Input: `{ url:string; device?: "desktop"|"tablet"|"mobile"; parity?: boolean; knobs?: {...} }`
  * Defaults: `device="desktop"`, `parity = (process.env.PARITY_MODE !== "false")`
  * Flow:

    1. Validate `url` and `device`.
    2. Call orchestrator (`makeAiHeatmapImage`) with cache enabled by env.
    3. Respond **200** `{ base64, meta }` where:

       * `meta.phase = "phase7"`
       * `meta.engine = "ai"`
       * `meta.ai = { model:"gpt-4o-mini", fallback:boolean, promptHash:string, cached?:boolean, requested, accepted, pruned, parity:boolean }`
  * **Remove/ignore** any `"engine":"legacy"` handling (return **400** with `{ error:"legacy engine is disabled" }` if passed).

### 6) `client/dev/ai-heatmap.html` (tiny harness page, new)

* A bare page with:

  * Inputs: URL, device select (desktop/tablet/mobile), a “Generate” button.
  * Shows the returned image (`<img src="...">`) and the meta JSON in a `<pre>`.
* Calls `POST /api/v1/heatmap` with the inputs.
* This is dev-only; no design polish needed.

---

## B) Error policy (AI-only)

* **400**: missing `url`, invalid `device`.
* **500**: only for screenshot/render **internal** errors you can’t recover from.

  * OpenAI failures must **not** cause 500 — use fallback hotspots.
* Response body on 500: `{ error: "INTERNAL_ERROR", details: "screenshot provider failed" }` (short and explicit).

---

## C) Defaults & bounds (keep visuals stable)

* Viewports: desktop `1920×1080`, tablet `1024×768`, mobile `414×896`.
* Renderer defaults = your Phase-5 choices:

  * `blendMode: "lighter"`
  * `alpha` (your known-good)
  * `kernelRadiusPx`, `kernelSigmaPx`, `clipMin/Max`, `ramp: "classic"`
    (Do **not** change defaults in this step.)
* Hotspot parity **ON by default** (`PARITY_MODE !== "false"`).

---

## D) Acceptance (use your Step-2 PowerShell smoketest)

All must pass:

1. **Happy path**

   * `POST /api/v1/heatmap { url, device:"desktop" }` → **200**, base64 PNG,
     meta.phase="phase7", meta.engine="ai", meta.ai.model="gpt-4o-mini".

2. **Device variants**

   * desktop/tablet/mobile → **200**, with `viewport` matching device map.

3. **Invalid inputs**

   * device "watch" → **400**
   * missing url → **400**

4. **Legacy disabled**

   * `engine:"legacy"` → **400** `{ error: "legacy engine is disabled" }`.

5. **Cache observable** (optional)

   * Call the same payload twice with `HOTSPOTS_CACHE="true"` → second response `meta.ai.cached === true`.

---

## E) Commit guidance

* `feat(ai): add in-memory hotspots cache and parity flag`
* `feat(api): finalize /api/v1/heatmap (AI-only, base64 envelope)`
* `feat(dev): add minimal client harness for AI heatmap`
* `chore(log): structured logs with cached + points`

---

This gives you a **complete, reliable heatmap feature** powered by the AI engine only, with caching and parity safety. If later you want to explore legacy, we can do it in a separate, isolated track without risking the main path.
